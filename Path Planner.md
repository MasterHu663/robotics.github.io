# Simultaneous Localization and Mapping

## Active SLAM

> Paper: A Survey on Active Simultaneous Localization and Mapping: State of the Art and New Frontiers

### 1. POMDP （部分可观察的马尔可夫决策过程）

**Def：**离散时间POMDP对智能体与其环境之间的关系进行建模。从形式讲，POMDP是一个7元组$(S,A,Z,T,O,R,\gamma)$，其中，

​	$S$是状态空间

​	$A$是动作空间

​	$Z$是观测空间

​	$T$是状态之间的条件转换概率的集合

​	$O$是观测的条件概率密度的集合

​	$R：S\times A\rightarrow\mathbb{R}$是奖励函数

​	$\gamma\in [0,1)$是折扣系数

与全部可观测的情形不同，POMDP中的智能体不能可靠地确定他们的真实状态，$s$。他们依赖于一种信念状态，$b_t(s_t)$

$$
b_t(s_t)=p(s_t\ |\ z_{1:t},a_{1:t-1})
$$
信念空间被定义为：
$$
B(s)=\{b:S\rightarrow \mathbb{R}\ |\ \int b(s)ds=1,b(s) \ge0\}
$$
为了评估未来动作的效用，智能体必须获知动作后的状态信念分布
$$
b_{t+1}(s_{t+1})=p(s_{t+1}\ |\ z_{t+1},a_t,b_t(s_t))
$$
由于未来的观测对于智能体是未知的，我们只能考虑其预测值，假定$b_t(s_t)$下智能体会执行$a_t$的动作，转移到另一状态，其状态的概率密度分布为$p(s_{t+1})$
$$
p(z_{t+1}|b_t(s_t),a_t)=\int\int o(s_{t+1})t(s_t,a_t)b_t(s_t)ds_tds_{t+1}
$$
其中，$o(s_{t+1})=p(z_{t+1}|s_{t+1})$为观测模型，$t(s_t,a_t)=p(s_{t+1}|s_t)$为动作模型

既然信念状态可以作为一个充分的数据，寻找POMDP的最优化策略可以转化为寻找信念集合$B(S)$下的MDP的最优策略，这样的MDP模型为5元组$(B,A,\tau,\rho,\gamma)$，其中，$\tau$为置信状态转移函数，$\rho$为信念状态的奖励函数
$$
\rho(b_t,a_t)=\int_Sb_t(s_t)r(s_t,a_t)ds_t
$$
与 “原始” POMDP 不同（每个动作只能从一个状态获得），在相应的信念 MDP 中，所有信念状态都允许所有动作，因为你（几乎）总是有一定的概率相信你处于任何（原始）状态。因此，$\pi$ 指定任何信念$b$的动作 $a=\pi(b)$，于是，我们将策略$\pi_t$定义为从状态的信念空间到动作的映射
$$
\pi_t:B(S)\rightarrow A
$$
最优策略为
$$
\pi^*(b)=\arg \max_\pi\sum_{t=0}^{\infty}E[\gamma^t\rho(b_t,\pi(b_t)) ]
$$

### 2. Travelling salesman problem （旅行商问题）

**问题内容：**给定一系列城市和每对城市之间的距离，求解访问每座城市一次并回到起始城市的最短回路。

#### Global Planner

##### 1. BFS & DFS 算法（Breadth-first search & Depth-first search）

DFS和BFS是两种搜索树和图的基本策略，一种往深处搜，一种往边上搜。 DFS常用于暴力搜索所有状态，BFS常用于搜索到达某一状态的最短路径。广度优先搜索在进一步遍历图中顶点之前，先访问当前顶点的所有邻接结点。深度优先搜索在搜索过程中访问某个顶点后，需要递归地访问此顶点的所有未访问过的相邻顶点。

BFS在编程时使用队列作为数据结构，先进先出（first in, first out）；DFS在编程时使用堆栈作为数据结构，先进后出（first in, last out）。

##### 2. 启发式搜索算法（Heuristic Algorithm）

以贪婪最佳优先算法（Greedy Best First Search, GBFS）为例。

GBFS使用的是优先队列（Priority Queue），最高优先级元素优先删除，first in, largest out。

在图搜索算法中，使用代价函数$f(n)$来作为优先级判断的标准，$f(n)$越小，优先级越高，反之，优先级越低。GBFS作为一种启发式搜索算法，使用启发评估函数$h(n)$作为代价函数，也就是$f(n)=h(n)$。$h(n)$是当前节点到终点的代价，它可以指引搜索算法往终点靠近，主要用欧氏距离或者曼哈顿距离来比表示。

但是往往会陷入局部最优解，无法找到最短路径。

##### 3. Dijkstra 算法

Dijkstra算法也是用优先队列作为openlist的数据结构，它和GBFS的区别在于代价函数$f(n)$的定义，Dijkstra算法的$f(n)$定义为$f(n) = g(n)$，其中$g(n)$表示从起点到当前点的移动代价。

有研究者提出了一种优化方法，即双向Dijkstra算法。其主要思想就是从起点和终点同时开始搜索，这样应该能够提升算法的效率。

##### 4. A* 算法

对比GBFS和Dijkstra算法，两者都采用优先队列作为openlist，而代价函数的不同导致两者具有不同的优点：GBFS用节点到目标点的距离作为代价函数，将搜索方向引向目标点，搜索效率高；而Dijkstra算法采用起点到当前扩展节点的移动代价作为代价函数，能够确保路径最优。

那么可不可以将两者的代价函数进行融合，从而**在保证路径最优的同时提高搜索效率**？答案是肯定的，融合后的算法就是**A\*算法**。

A*算法也是一种启发式算法，它的代价函数表示为：$f(n)=g(n)+h(n)$，其中，$g(n)$为起点到当前扩展节点的移动代价函数，$h(n)$是启发函数，用节点到目标点的距离函数来表示。

##### 5. JPS 算法（Jump Point Search）

JPS算法被视为A\*算法的一种改进算法，保留了A\*算法的主体框架，区别在于：A*算法是将当前节点的所有未访问邻居节点加入openlist，而JPS则是使用一些方法将有“价值”的节点加入openlist。

A\*算法在扩展节点时会把节点所有邻居都考虑进去，这样openlist中点的数量很多，搜索效率较慢，例如在无遮挡的情况下，往往会有多条等价路径，而我们希望起点到终点实际只取其中一条路径，而该路径外的其他节点没有必要放入openlist，不希望加入没有必要的邻居。

其次，我们还希望直线方向上中途的点不用放入openlist，如果只放入每段直线子路径的起点和终点，那openlist又可以少放入很多没必要的节点

JPS的算法核心就是寻找跳点，在JPS中，就是将跳点加入openlist。

###### 5.1 强迫邻居

定义：节点x的8个邻居中有障碍，且x的父节点p经过x到达n的距离代价比不经过x到达n的任意路径的距离代价小，则称n是x的强迫邻居。

###### 5.2 跳点

满足以下三个条件：

- 节点x是终点/起点
- 节点x至少有一个强迫邻居
- 如果父节点在斜方向（意味着这是斜向搜索），节点x的水平或垂直方向上有满足条件a，b的点

##### 6. PRM 算法（Probabilistic Road Map）

PRM是一种基于图搜索的方法，它将连续空间转换成离散空间，再利用A\*等搜索算法在路线图上寻找路径。分为两个步骤：学习阶段和查询阶段

###### 6.1 学习阶段

学习阶段的主要目标是在空间中按照一定分布（如均匀分布）采样N个点，利用碰撞检测等手段去除存在障碍物内的点，再利用线段将点与点进行连线。

点与点连线的准则：

- 起点与终点节点要被连接到网络中
- 被连接的两个点之间满足一定距离约束，例如最近邻的几个点；此处，如果没有这个约束的话，最糟糕的情况是得到了全连通图，使得后期路径规划运行时间增加
- 如果两个点之间的连线经过障碍物，则这条线段不可连接

**采样点的数量**和**采样点间存在通路的最大距离**是路径规划与否的关键。

- 采样点的数量太少，可能会导致路径规划生成失败，不能生成完整的图；采样点的数量太多，搜索到的路径会逐渐接近最短路径
- 最大距离太小，会导致规划失败；最大距离太大，会降低搜索效率

###### 6.2 查询阶段

查询阶段的主要目标是在学习阶段构建的图中，基于起始和终点节点，寻找最短路径，常用的算法是采用A\*等算法。此时，再利用A\*算法，搜索过程会提升很大的性能。原因在于，PRM得到的图数据结构的复杂度远远低于直接将空间进行数据建模。

PRM算法参数少、结构简单，能够提高高维空间搜索效率，也能在生成概率路图时添加机器人的运动学约束，使最终生成的路径符合机器人的运动学模型。同时，随机采样得到的概率路图只需要建立一次就可以一直使用，重用性强。但由于采样过程是完全随机的，得到的节点大多数都偏离最终路径，会增加额外的计算量。

##### 7. RRT 算法（Rapidly-exploring Random Tree）

RRT算法是一种单查询（single-query）算法，目标是**尽可能快的找到一条从起点到终点的可行路径**。它的搜索过程类似于一棵树不断生长、向四周扩散的过程，它以起点作为根节点构建一棵搜索树$T$。

###### 7.1 Basic RRT 算法

- 从自由空间中随机采样得到采样点$X_{rand}$
- 从搜索树T中找到距离采样点$X_{rand}$最近的节点$X_{near}$
- 计算$X_{near}$和$X_{rand}$之间的距离。如果距离大于步长$u$且通过碰撞检测，则从$X_{near}$向$X_{rand}$移动步长$u$后得到新节点$X_{new}$；否则$X_{rand}$位置生成新节点$X_{new}$
- 如果$X_{near}$和$X_{new}$间存在直线通路，则将$X_{new}$加入搜索树$T$，它的父节点为$X_{near}$；

在采样时**以一定的概率直接采样终点作为** $x_{rand}$ ，加快搜索速度。但是RRT算法只是一种单查询算法，只管尽快找到可行路径，所以最终路径并不是最优的，甚至会非常“绕”。

###### 7.2 RRT-Connect

RRT-connet在RRT的基础上引入了双树扩展环节，分别**以起点和目标点为根节点生成两颗树进行双向扩展**，当两棵树建立连接时可认为路径规划成功。通过一次采样得到一个采样点 $x_{rand}$，然后两棵搜索树同时向采样点 $x_{rand}$ 方向进行扩展，加快两棵树建立连接的速度。相较于单树扩展的RRT算法，RRT-Connect加入了**启发式**步骤，加快了搜索速度，对于狭窄通道也具有较好的效果。

###### 7.3 RRT\*

RRT\*算法是一种渐进最优算法。算法流程与RRT算法流程基本相同，不同之处就在于最后加入将$X_{new}$加入搜索树$T$时**父节点的选择策略**。

- Connect along a minimum-cost：为$X_{new}$附近以定义的半径范围内寻找“近邻”，作为替换$X_{new}$父节点的备选。依次计算**“近邻”节点到起点的路径代价加上$X_{new}$到每个“近邻“的路径代价**，选择路径代价最小的”近邻“节点作为$X_{new}$的父节点。
- Rewrite the tree：在为$X_{new}$重新选择父节点之后，为进一步使得随机数节点间连接的代价尽量小，为随机数进行重新布线。或者说，**如果近邻节点的父节点改为$X_{new}$可以减小路径代价，则进行更改**。

#### Local Planner

##### 1. DWA算法

